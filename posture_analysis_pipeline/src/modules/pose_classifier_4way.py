# ===============================================
# ğŸ“Œ 3í´ë˜ìŠ¤ ìì„¸ ë¶„ë¥˜ ëª¨ë“ˆ (4way ëª¨ë¸)
#
# âœ… íŠ¹ì§•:
# - ì •ë©´, ì¢Œì¸¡ë©´, ìš°ì¸¡ë©´ 3í´ë˜ìŠ¤ ë¶„ë¥˜
# - MediaPipe ëœë“œë§ˆí¬ ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ
# - RandomForest ë¶„ë¥˜ê¸° ì‚¬ìš©
# - íŒŒì´í”„ë¼ì¸ í†µí•©ìš© ëª¨ë“ˆ
# ===============================================

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class PoseClassifier4Way:
    def __init__(self):
        self.model = None
        self.scaler = None
        self.is_trained = False
        self.classes = ['ì •ë©´', 'ì¢Œì¸¡ë©´', 'ìš°ì¸¡ë©´']
        
    def normalize_coordinates(self, landmarks):
        """ì–´ê¹¨ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ì¢Œí‘œ ì •ê·œí™”"""
        normalized = []
        
        # ì–´ê¹¨ ì¤‘ì‹¬ì  ê³„ì‚° (ëœë“œë§ˆí¬ 11, 12)
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_center_x = (landmarks[11] + landmarks[12]) / 2
            shoulder_center_y = (landmarks[11+1] + landmarks[12+1]) / 2
        else:
            shoulder_center_x, shoulder_center_y = 0, 0
            
        # ì–´ê¹¨ ë„ˆë¹„ë¡œ ì •ê·œí™”
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_width = abs(landmarks[11] - landmarks[12])
        else:
            shoulder_width = 1.0
            
        # ê° ëœë“œë§ˆí¬ë¥¼ ì–´ê¹¨ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
        for i in range(0, len(landmarks), 2):
            if landmarks[i] != -1 and landmarks[i+1] != -1:
                norm_x = (landmarks[i] - shoulder_center_x) / max(shoulder_width, 0.001)
                norm_y = (landmarks[i+1] - shoulder_center_y) / max(shoulder_width, 0.001)
                normalized.extend([norm_x, norm_y])
            else:
                normalized.extend([0, 0])
                
        return normalized
    
    def calculate_angles(self, landmarks):
        """ì£¼ìš” ê°ë„ ê³„ì‚°"""
        angles = []
        
        # ëª©-ì–´ê¹¨-íŒ”ê¿ˆì¹˜ ê°ë„ (ëœë“œë§ˆí¬ 0-11-12)
        if landmarks[0] != -1 and landmarks[11] != -1 and landmarks[12] != -1:
            dx1 = landmarks[11] - landmarks[0]
            dy1 = landmarks[11+1] - landmarks[0+1]
            dx2 = landmarks[12] - landmarks[11]
            dy2 = landmarks[12+1] - landmarks[11+1]
            
            dot_product = dx1*dx2 + dy1*dy2
            mag1 = np.sqrt(dx1*dx1 + dy1*dy1)
            mag2 = np.sqrt(dx2*dx2 + dy2*dy2)
            
            if mag1 > 0 and mag2 > 0:
                cos_angle = dot_product / (mag1 * mag2)
                cos_angle = np.clip(cos_angle, -1.0, 1.0)
                angle = np.arccos(cos_angle)
                angles.append(np.degrees(angle))
            else:
                angles.append(0)
        else:
            angles.append(0)
        
        return angles
    
    def extract_features(self, landmarks):
        """íŠ¹ì§• ì¶”ì¶œ (4way ëª¨ë¸ê³¼ ë™ì¼í•œ êµ¬ì¡°)"""
        features = []
        
        # 1. ì •ê·œí™”ëœ ì¢Œí‘œ (ì¤‘ìš”í•œ ë¶€ìœ„ë§Œ ì„ íƒ)
        normalized_coords = self.normalize_coordinates(landmarks)
        
        # ë¨¸ë¦¬, ëª©, ì–´ê¹¨ ë¶€ìœ„ë§Œ ì„ íƒ (ëœë“œë§ˆí¬ 0-12)
        important_landmarks = []
        for i in range(0, 26, 2):  # 0-12ë²ˆ ëœë“œë§ˆí¬ë§Œ
            important_landmarks.extend([normalized_coords[i], normalized_coords[i+1]])
        
        features.extend(important_landmarks)
        
        # 2. ê°ë„ íŠ¹ì§•
        angles = self.calculate_angles(landmarks)
        features.extend(angles)
        
        # 3. ì–´ê¹¨ ë¹„ìœ¨
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_width = abs(landmarks[11] - landmarks[12])
            shoulder_height = abs(landmarks[11+1] - landmarks[12+1])
            shoulder_ratio = shoulder_width / max(shoulder_height, 0.001)
            features.append(shoulder_ratio)
        else:
            features.append(1.0)
        
        # 4. ëŒ€ì¹­ì„± íŠ¹ì§•
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_symmetry = abs(landmarks[11+1] - landmarks[12+1])
            features.append(shoulder_symmetry)
        else:
            features.append(0)
        
        # 5. ì–´ê¹¨ ë°©í–¥ íŠ¹ì§• (ì¢Œì¸¡ë©´/ìš°ì¸¡ë©´ êµ¬ë¶„ìš©)
        if landmarks[11] != -1 and landmarks[12] != -1:
            # ì™¼ìª½ ì–´ê¹¨ê°€ ë” ìœ„ì— ìˆëŠ”ì§€ (ì¢Œì¸¡ë©´ íŠ¹ì§•)
            left_shoulder_higher = landmarks[11+1] - landmarks[12+1]
            features.append(left_shoulder_higher)
            
            # ì–´ê¹¨ì˜ xì¶• ì°¨ì´ (ì¸¡ë©´ êµ¬ë¶„ìš©)
            shoulder_x_diff = landmarks[11] - landmarks[12]
            features.append(shoulder_x_diff)
        else:
            features.extend([0, 0])
        
        return features
    
    def prepare_data(self, csv_file):
        """CSV íŒŒì¼ì—ì„œ ë°ì´í„° ì¤€ë¹„"""
        print(f"ë°ì´í„° ë¡œë“œ ì¤‘: {csv_file}")
        
        # CSV íŒŒì¼ ì½ê¸°
        df = pd.read_csv(csv_file)
        print(f"ì´ ë°ì´í„° ìˆ˜: {len(df)}")
        
        # ë¼ë²¨ ë¶„í¬ í™•ì¸
        label_counts = df['label'].value_counts().sort_index()
        print("ë¼ë²¨ ë¶„í¬:")
        for label, count in label_counts.items():
            label_name = ['ê¸°íƒ€', 'ì •ë©´', 'ì¢Œì¸¡ë©´', 'ìš°ì¸¡ë©´'][label]
            print(f"  ë¼ë²¨ {label} ({label_name}): {count}ê°œ")
        
        # ë¼ë²¨ 0 (ê¸°íƒ€) ì œì™¸í•˜ê³  3í´ë˜ìŠ¤ë§Œ ì‚¬ìš©
        df_filtered = df[df['label'] > 0].copy()
        print(f"í•„í„°ë§ëœ ë°ì´í„° ìˆ˜: {len(df_filtered)}")
        
        # íŠ¹ì§• ì¶”ì¶œ
        X = []
        y = []
        
        for _, row in df_filtered.iterrows():
            # ëœë“œë§ˆí¬ ì¢Œí‘œ ì¶”ì¶œ (33ê°œ ëœë“œë§ˆí¬ * 2ì¢Œí‘œ = 66ê°œ)
            landmarks = []
            for i in range(33):
                x_col = f'landmark_{i}_x'
                y_col = f'landmark_{i}_y'
                if x_col in row and y_col in row:
                    landmarks.extend([row[x_col], row[y_col]])
                else:
                    landmarks.extend([-1, -1])  # ëœë“œë§ˆí¬ê°€ ì—†ìœ¼ë©´ -1
            
            # íŠ¹ì§• ì¶”ì¶œ
            features = self.extract_features(landmarks)
            X.append(features)
            
            # ë¼ë²¨ ì¡°ì • (1,2,3 -> 0,1,2)
            y.append(row['label'] - 1)
        
        return np.array(X), np.array(y)
    
    def train_model(self, X, y):
        """ëª¨ë¸ í›ˆë ¨"""
        print("ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # RandomForest ë¶„ë¥˜ê¸° í›ˆë ¨
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        # ì„±ëŠ¥ í‰ê°€
        y_pred = self.model.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)
        
        # êµì°¨ ê²€ì¦
        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=5)
        
        print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.3f}")
        print(f"êµì°¨ ê²€ì¦ ì ìˆ˜: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
        
        # ë¶„ë¥˜ ë¦¬í¬íŠ¸
        print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
        print(classification_report(y_test, y_pred, target_names=self.classes))
        
        # í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(y_test, y_pred)
        print("\ní˜¼ë™ í–‰ë ¬:")
        print(cm)
        
        # íŠ¹ì§• ì¤‘ìš”ë„
        feature_importance = self.model.feature_importances_
        print(f"\nì´ íŠ¹ì§• ìˆ˜: {len(feature_importance)}")
        print("ìƒìœ„ 10ê°œ íŠ¹ì§• ì¤‘ìš”ë„:")
        top_indices = np.argsort(feature_importance)[-10:][::-1]
        for i, idx in enumerate(top_indices):
            print(f"  {i+1}. íŠ¹ì§• {idx}: {feature_importance[idx]:.4f}")
        
        self.is_trained = True
        return accuracy, cv_scores.mean()
    
    def save_model(self, model_path):
        """ëª¨ë¸ ì €ì¥"""
        if not self.is_trained:
            print("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'is_trained': self.is_trained,
            'classes': self.classes
        }
        
        with open(model_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"ëª¨ë¸ì´ {model_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def load_model(self, model_path):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.is_trained = model_data['is_trained']
            self.classes = model_data.get('classes', ['ì •ë©´', 'ì¢Œì¸¡ë©´', 'ìš°ì¸¡ë©´'])
            
            print(f"ëª¨ë¸ì´ {model_path}ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
        except Exception as e:
            print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def predict(self, landmarks):
        """ë‹¨ì¼ ì˜ˆì¸¡"""
        if not self.is_trained:
            return None, None
        
        features = self.extract_features(landmarks)
        features_scaled = self.scaler.transform([features])
        
        prediction = self.model.predict(features_scaled)[0]
        probability = self.model.predict_proba(features_scaled)[0]
        
        return prediction, probability
    
    def create_visualizations(self, X, y, output_dir):
        """ì‹œê°í™” ìƒì„±"""
        if not self.is_trained:
            print("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
        X_scaled = self.scaler.transform(X)
        y_pred = self.model.predict(X_scaled)
        cm = confusion_matrix(y, y_pred)
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=self.classes, yticklabels=self.classes)
        plt.title('3í´ë˜ìŠ¤ ìì„¸ ë¶„ë¥˜ í˜¼ë™ í–‰ë ¬')
        plt.ylabel('ì‹¤ì œ')
        plt.xlabel('ì˜ˆì¸¡')
        plt.tight_layout()
        plt.savefig(output_path / 'confusion_matrix_4way.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # íŠ¹ì§• ì¤‘ìš”ë„ ì‹œê°í™”
        feature_importance = self.model.feature_importances_
        top_indices = np.argsort(feature_importance)[-15:][::-1]
        
        plt.figure(figsize=(10, 8))
        plt.barh(range(len(top_indices)), feature_importance[top_indices])
        plt.yticks(range(len(top_indices)), [f'íŠ¹ì§• {i}' for i in top_indices])
        plt.xlabel('ì¤‘ìš”ë„')
        plt.title('ìƒìœ„ 15ê°œ íŠ¹ì§• ì¤‘ìš”ë„')
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.savefig(output_path / 'feature_importance_4way.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ì‹œê°í™”ê°€ {output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ë°ì´í„° ì¤€ë¹„
    csv_file = '../../test/data/P1_0706/pose_landmarks_P1_merged.csv'
    X, y = prepare_data(csv_file)
    
    # ëª¨ë¸ í›ˆë ¨
    classifier = PoseClassifier4Way()
    accuracy, cv_score = classifier.train_model(X, y)
    
    # ëª¨ë¸ ì €ì¥
    model_path = 'pose_classifier_4way_model.pkl'
    classifier.save_model(model_path)
    
    # ì‹œê°í™” ìƒì„±
    output_dir = '../../data/results/visualization'
    classifier.create_visualizations(X, y, output_dir)
    
    print(f"\ní›ˆë ¨ ì™„ë£Œ!")
    print(f"ìµœì¢… ì •í™•ë„: {accuracy:.3f}")
    print(f"êµì°¨ ê²€ì¦ ì ìˆ˜: {cv_score:.3f}")

if __name__ == "__main__":
    main() 