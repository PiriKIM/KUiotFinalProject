# ===============================================
# ğŸ“Œ ì‹¤ì‹œê°„ 3í´ë˜ìŠ¤ ìì„¸ ë¶„ë¥˜ ì‹œìŠ¤í…œ (4way ëª¨ë¸ ì‚¬ìš©)
#
# âœ… íŠ¹ì§•:
# - pose_classifier_4way_model.pkl ëª¨ë¸ ì‚¬ìš©
# - 3í´ë˜ìŠ¤ ë¶„ë¥˜: ì •ë©´(1), ì¢Œì¸¡ë©´(2), ìš°ì¸¡ë©´(3)
# - ì‹¤ì‹œê°„ ì›¹ìº  ë¶„ë¥˜ ë° ì½˜ì†” ì¶œë ¥
# - í•œê¸€ í…ìŠ¤íŠ¸ ë Œë”ë§ ì§€ì›
# ===============================================

import cv2
import mediapipe as mp
import numpy as np
import pickle
import time
from PIL import Image, ImageDraw, ImageFont
import warnings
warnings.filterwarnings('ignore')

# MediaPipe ì´ˆê¸°í™”
mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose

# ì „ì—­ í°íŠ¸ ë³€ìˆ˜
_global_font = None
_font_loaded = False

def get_korean_font(font_size=20):
    """í•œê¸€ í°íŠ¸ë¥¼ í•œ ë²ˆë§Œ ë¡œë“œí•˜ì—¬ ì¬ì‚¬ìš©"""
    global _global_font, _font_loaded
    
    if _font_loaded and _global_font:
        return _global_font
    
    # í•œê¸€ í°íŠ¸ ë¡œë“œ (ì—¬ëŸ¬ í°íŠ¸ ê²½ë¡œ ì‹œë„)
    font_paths = [
        "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
        "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
        "/System/Library/Fonts/Arial.ttf",  # macOS
        "C:/Windows/Fonts/malgun.ttf",      # Windows
        "/home/woo/kuBig2025/opencv/data/NanumPenScript-Regular.ttf"  # ì‚¬ìš©ì ì§€ì • ê²½ë¡œ
    ]
    
    for font_path in font_paths:
        try:
            _global_font = ImageFont.truetype(font_path, font_size)
            _font_loaded = True
            print(f"í•œê¸€ í°íŠ¸ ë¡œë“œ ì„±ê³µ: {font_path}")
            break
        except Exception as e:
            continue
    
    if not _font_loaded:
        # í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
        _global_font = ImageFont.load_default()
        print("ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
        _font_loaded = True
    
    return _global_font

def put_korean_text(img, text, position, font_size=20, color=(255, 255, 255)):
    """PILì„ ì‚¬ìš©í•œ í•œê¸€ í…ìŠ¤íŠ¸ ë Œë”ë§ í•¨ìˆ˜"""
    try:
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)
        
        # í°íŠ¸ ê°€ì ¸ì˜¤ê¸°
        font = get_korean_font(font_size)
        
        # ìƒ‰ìƒì„ RGBë¡œ ë³€í™˜ (PILì€ RGB ì‚¬ìš©)
        color_rgb = (color[2], color[1], color[0])  # BGR to RGB
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        draw.text(position, text, font=font, fill=color_rgb)
        
        # OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜
        img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        return img_cv
        
    except Exception as e:
        print(f"PIL í•œê¸€ í…ìŠ¤íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ OpenCV í…ìŠ¤íŠ¸ ì‚¬ìš©
        cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        return img

class RealTimePoseClassifier4Way:
    def __init__(self, model_path='pose_classifier_4way_model.pkl'):
        self.model = None
        self.scaler = None
        self.is_trained = False
        self.classes = ['ì •ë©´', 'ì¢Œì¸¡ë©´', 'ìš°ì¸¡ë©´']
        self.load_model(model_path)
        
    def normalize_coordinates(self, landmarks):
        """ì–´ê¹¨ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ì¢Œí‘œ ì •ê·œí™”"""
        normalized = []
        
        # ì–´ê¹¨ ì¤‘ì‹¬ì  ê³„ì‚° (ëœë“œë§ˆí¬ 11, 12)
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_center_x = (landmarks[11] + landmarks[12]) / 2
            shoulder_center_y = (landmarks[11+1] + landmarks[12+1]) / 2
        else:
            shoulder_center_x, shoulder_center_y = 0, 0
            
        # ì–´ê¹¨ ë„ˆë¹„ë¡œ ì •ê·œí™”
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_width = abs(landmarks[11] - landmarks[12])
        else:
            shoulder_width = 1.0
            
        # ê° ëœë“œë§ˆí¬ë¥¼ ì–´ê¹¨ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
        for i in range(0, len(landmarks), 2):
            if landmarks[i] != -1 and landmarks[i+1] != -1:
                norm_x = (landmarks[i] - shoulder_center_x) / max(shoulder_width, 0.001)
                norm_y = (landmarks[i+1] - shoulder_center_y) / max(shoulder_width, 0.001)
                normalized.extend([norm_x, norm_y])
            else:
                normalized.extend([0, 0])
                
        return normalized
    
    def calculate_angles(self, landmarks):
        """ì£¼ìš” ê°ë„ ê³„ì‚°"""
        angles = []
        
        # ëª©-ì–´ê¹¨-íŒ”ê¿ˆì¹˜ ê°ë„ (ëœë“œë§ˆí¬ 0-11-12)
        if landmarks[0] != -1 and landmarks[11] != -1 and landmarks[12] != -1:
            dx1 = landmarks[11] - landmarks[0]
            dy1 = landmarks[11+1] - landmarks[0+1]
            dx2 = landmarks[12] - landmarks[11]
            dy2 = landmarks[12+1] - landmarks[11+1]
            
            dot_product = dx1*dx2 + dy1*dy2
            mag1 = np.sqrt(dx1*dx1 + dy1*dy1)
            mag2 = np.sqrt(dx2*dx2 + dy2*dy2)
            
            if mag1 > 0 and mag2 > 0:
                cos_angle = dot_product / (mag1 * mag2)
                cos_angle = np.clip(cos_angle, -1.0, 1.0)
                angle = np.arccos(cos_angle)
                angles.append(np.degrees(angle))
            else:
                angles.append(0)
        else:
            angles.append(0)
        
        return angles
    
    def extract_features(self, landmarks):
        """íŠ¹ì§• ì¶”ì¶œ (4way ëª¨ë¸ê³¼ ë™ì¼í•œ êµ¬ì¡°)"""
        features = []
        
        # 1. ì •ê·œí™”ëœ ì¢Œí‘œ (ì¤‘ìš”í•œ ë¶€ìœ„ë§Œ ì„ íƒ)
        normalized_coords = self.normalize_coordinates(landmarks)
        
        # ë¨¸ë¦¬, ëª©, ì–´ê¹¨ ë¶€ìœ„ë§Œ ì„ íƒ (ëœë“œë§ˆí¬ 0-12)
        important_landmarks = []
        for i in range(0, 26, 2):  # 0-12ë²ˆ ëœë“œë§ˆí¬ë§Œ
            important_landmarks.extend([normalized_coords[i], normalized_coords[i+1]])
        
        features.extend(important_landmarks)
        
        # 2. ê°ë„ íŠ¹ì§•
        angles = self.calculate_angles(landmarks)
        features.extend(angles)
        
        # 3. ì–´ê¹¨ ë¹„ìœ¨
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_width = abs(landmarks[11] - landmarks[12])
            shoulder_height = abs(landmarks[11+1] - landmarks[12+1])
            shoulder_ratio = shoulder_width / max(shoulder_height, 0.001)
            features.append(shoulder_ratio)
        else:
            features.append(1.0)
        
        # 4. ëŒ€ì¹­ì„± íŠ¹ì§•
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_symmetry = abs(landmarks[11+1] - landmarks[12+1])
            features.append(shoulder_symmetry)
        else:
            features.append(0)
        
        # 5. ì–´ê¹¨ ë°©í–¥ íŠ¹ì§• (ì¢Œì¸¡ë©´/ìš°ì¸¡ë©´ êµ¬ë¶„ìš©) - 4way ëª¨ë¸ê³¼ ë™ì¼
        if landmarks[11] != -1 and landmarks[12] != -1:
            # ì™¼ìª½ ì–´ê¹¨ê°€ ë” ìœ„ì— ìˆëŠ”ì§€ (ì¢Œì¸¡ë©´ íŠ¹ì§•)
            left_shoulder_higher = landmarks[11+1] - landmarks[12+1]
            features.append(left_shoulder_higher)
            
            # ì–´ê¹¨ì˜ xì¶• ì°¨ì´ (ì¸¡ë©´ êµ¬ë¶„ìš©)
            shoulder_x_diff = landmarks[11] - landmarks[12]
            features.append(shoulder_x_diff)
        else:
            features.extend([0, 0])
        
        return features
    
    def load_model(self, model_path):
        """4way ëª¨ë¸ ë¡œë“œ"""
        try:
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.is_trained = model_data['is_trained']
            self.classes = model_data.get('classes', ['ì •ë©´', 'ì¢Œì¸¡ë©´', 'ìš°ì¸¡ë©´'])
            
            print(f"4way ëª¨ë¸ì´ {model_path}ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"í´ë˜ìŠ¤: {self.classes}")
        except Exception as e:
            print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ë¨¼ì € 4way ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
            self.is_trained = False
    
    def predict(self, landmarks):
        """ì‹¤ì‹œê°„ ì˜ˆì¸¡ (3í´ë˜ìŠ¤)"""
        if not self.is_trained or self.model is None or self.scaler is None:
            return None, None
        
        try:
            features = self.extract_features(landmarks)
            features_scaled = self.scaler.transform([features])
            
            prediction = self.model.predict(features_scaled)[0]
            probability = self.model.predict_proba(features_scaled)[0]
            
            return prediction, probability
        except Exception as e:
            print(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return None, None

def landmarks_to_array(landmarks):
    """MediaPipe landmarksë¥¼ ë°°ì—´ë¡œ ë³€í™˜"""
    landmarks_array = []
    for landmark in landmarks:
        landmarks_array.extend([landmark.x, landmark.y])
    return landmarks_array

def main():
    print("ì‹¤ì‹œê°„ 3í´ë˜ìŠ¤ ìì„¸ ë¶„ë¥˜ ì‹œìŠ¤í…œ ì‹œì‘...")
    
    # 4way ìì„¸ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
    classifier = RealTimePoseClassifier4Way()
    
    if not classifier.is_trained:
        print("4way ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        return
    
    # ì›¹ìº  ì—´ê¸° (ì—¬ëŸ¬ ì¹´ë©”ë¼ ì‹œë„)
    cap = None
    for camera_id in [0, 1, 2]:
        try:
            cap = cv2.VideoCapture(camera_id)
            if cap.isOpened():
                print(f"ì¹´ë©”ë¼ {camera_id} ì—°ê²° ì„±ê³µ")
                break
            else:
                cap.release()
        except Exception as e:
            print(f"ì¹´ë©”ë¼ {camera_id} ì—°ê²° ì‹¤íŒ¨: {e}")
            if cap:
                cap.release()
    
    if cap is None or not cap.isOpened():
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì¹´ë©”ë¼ ì„¤ì •
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    # ì°½ ìƒì„± ë° ì„¤ì •
    window_name = 'ì‹¤ì‹œê°„ 3í´ë˜ìŠ¤ ìì„¸ ë¶„ë¥˜ ì‹œìŠ¤í…œ'
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, 1280, 720)
    
    # MediaPipe Pose ì´ˆê¸°í™”
    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        print("ì›¹ìº ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ESC í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.")
        
        frame_count = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                print("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                break
            
            frame_count += 1
            
            # BGR â†’ RGB ë³€í™˜
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            
            # í¬ì¦ˆ ì¶”ë¡  ì‹¤í–‰
            results = pose.process(image)
            
            # ê²°ê³¼ í‘œì‹œë¥¼ ìœ„í•´ ë‹¤ì‹œ BGRë¡œ ë³€í™˜
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            # ì¢Œìš°ë°˜ì „ (ê±°ìš¸ ëª¨ë“œ) - ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸° ì „ì— ìˆ˜í–‰
            image = cv2.flip(image, 1)
            
            # í™”ë©´ì— ê¸°ë³¸ ì •ë³´ í‘œì‹œ
            h, w, _ = image.shape
            
            # ì œëª© í‘œì‹œ
            title_text = "ì‹¤ì‹œê°„ 3í´ë˜ìŠ¤ ìì„¸ ë¶„ë¥˜ ì‹œìŠ¤í…œ"
            image = put_korean_text(image, title_text, (10, 30), 24, (255, 255, 255))
            
            # ê´€ì ˆ ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
            if results.pose_landmarks:
                # ëœë“œë§ˆí¬ë¥¼ ë°°ì—´ë¡œ ë³€í™˜
                landmarks_array = landmarks_to_array(results.pose_landmarks.landmark)
                
                # ìì„¸ ë¶„ë¥˜ ì˜ˆì¸¡
                prediction, probability = classifier.predict(landmarks_array)
                
                if prediction is not None and probability is not None:
                    # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
                    pose_type = classifier.classes[prediction - 1] if 1 <= prediction <= 3 else "ì•Œ ìˆ˜ ì—†ìŒ"
                    confidence = max(probability)
                    
                    # ìƒ‰ìƒ ì„¤ì • (ì •ë©´: ì´ˆë¡, ì¢Œì¸¡ë©´: íŒŒë‘, ìš°ì¸¡ë©´: ì£¼í™©)
                    if prediction == 1:  # ì •ë©´
                        color = (0, 255, 0)
                    elif prediction == 2:  # ì¢Œì¸¡ë©´
                        color = (255, 0, 0)
                    elif prediction == 3:  # ìš°ì¸¡ë©´
                        color = (0, 165, 255)  # ì£¼í™©ìƒ‰
                    else:
                        color = (255, 255, 255)
                    
                    # ê²°ê³¼ í…ìŠ¤íŠ¸
                    result_text = f"Posture: {pose_type}"
                    confidence_text = f"Reliability: {confidence:.1%}"
                    
                    # í™”ë©´ì— ê²°ê³¼ í‘œì‹œ
                    image = put_korean_text(image, result_text, (10, 70), 32, color)
                    image = put_korean_text(image, confidence_text, (10, 110), 20, (255, 255, 255))
                    
                    # ìƒì„¸ í™•ë¥  ì •ë³´
                    front_prob = probability[0] if len(probability) > 0 else 0
                    left_prob = probability[1] if len(probability) > 1 else 0
                    right_prob = probability[2] if len(probability) > 2 else 0
                    
                    detail_text1 = f"Front Probability: {front_prob:.1%}"
                    detail_text2 = f"Left Probability: {left_prob:.1%}"
                    detail_text3 = f"Right Probability: {right_prob:.1%}"
                    
                    image = put_korean_text(image, detail_text1, (10, 140), 16, (0, 255, 0))
                    image = put_korean_text(image, detail_text2, (10, 160), 16, (255, 0, 0))
                    image = put_korean_text(image, detail_text3, (10, 180), 16, (0, 165, 255))
                    
                    # ì½˜ì†”ì— ê²°ê³¼ ì¶œë ¥ (1ì´ˆë§ˆë‹¤)
                    current_time = time.time()
                    if not hasattr(main, 'last_print_time'):
                        main.last_print_time = 0
                    
                    if current_time - main.last_print_time >= 1.0:  # 1ì´ˆë§ˆë‹¤ ì¶œë ¥
                        print(f"[{time.strftime('%H:%M:%S')}] ìì„¸: {pose_type} (ì‹ ë¢°ë„: {confidence:.1%})")
                        print(f"  - ì •ë©´ í™•ë¥ : {front_prob:.1%}")
                        print(f"  - ì¢Œì¸¡ë©´ í™•ë¥ : {left_prob:.1%}")
                        print(f"  - ìš°ì¸¡ë©´ í™•ë¥ : {right_prob:.1%}")
                        
                        # ì£¼ìš” ëœë“œë§ˆí¬ ì¢Œí‘œ ì¶œë ¥
                        print("  - ì£¼ìš” ëœë“œë§ˆí¬ ì¢Œí‘œ:")
                        key_landmarks = [
                            (0, "NOSE", "ì½”"),
                            (7, "LEFT_EAR", "ì™¼ìª½ ê·€"),
                            (8, "RIGHT_EAR", "ì˜¤ë¥¸ìª½ ê·€"),
                            (11, "LEFT_SHOULDER", "ì™¼ìª½ ì–´ê¹¨"),
                            (12, "RIGHT_SHOULDER", "ì˜¤ë¥¸ìª½ ì–´ê¹¨"),
                            (23, "LEFT_HIP", "ì™¼ìª½ ì—‰ë©ì´"),
                            (24, "RIGHT_HIP", "ì˜¤ë¥¸ìª½ ì—‰ë©ì´")
                        ]
                        
                        for idx, name, korean in key_landmarks:
                            if idx * 2 < len(landmarks_array):
                                x = landmarks_array[idx * 2]
                                y = landmarks_array[idx * 2 + 1]
                                print(f"    {name:15s} ({korean:8s}): x={x:.3f}, y={y:.3f}")
                        
                        print("-" * 40)
                        main.last_print_time = current_time
                
                # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸° - ì¢Œìš°ë°˜ì „ëœ ì´ë¯¸ì§€ì— ë§ì¶° ì¢Œí‘œ ë³€í™˜
                # ì¢Œìš°ë°˜ì „ì„ ê³ ë ¤í•˜ì—¬ xì¢Œí‘œë¥¼ ë°˜ì „
                flipped_landmarks = results.pose_landmarks
                for landmark in flipped_landmarks.landmark:
                    # xì¢Œí‘œë¥¼ ë°˜ì „ (1 - x)
                    landmark.x = 1.0 - landmark.x
                
                # ë°˜ì „ëœ ëœë“œë§ˆí¬ë¡œ ê·¸ë¦¬ê¸°
                mp_drawing.draw_landmarks(
                    image, 
                    flipped_landmarks, 
                    mp_pose.POSE_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                    mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)
                )
                
                # ì–´ê¹¨ ê±°ë¦¬ ì •ë³´ í‘œì‹œ (ë””ë²„ê¹…ìš©) - ë°˜ì „ëœ ì¢Œí‘œ ì‚¬ìš©
                left_shoulder = flipped_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]
                right_shoulder = flipped_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]
                shoulder_distance = abs(left_shoulder.x - right_shoulder.x)
                distance_text = f"ì–´ê¹¨ ê±°ë¦¬: {shoulder_distance:.3f}"
                image = put_korean_text(image, distance_text, (10, 220), 14, (255, 255, 255))
                
            else:
                # ì‚¬ëŒì´ ê°ì§€ë˜ì§€ ì•Šì„ ë•Œ
                no_person_text = "ì‚¬ëŒì´ ê°ì§€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
                image = put_korean_text(image, no_person_text, (10, 70), 24, (0, 0, 255))
                
                # ì½˜ì†”ì— ìƒíƒœ ì¶œë ¥ (1ì´ˆë§ˆë‹¤)
                current_time = time.time()
                if not hasattr(main, 'last_print_time'):
                    main.last_print_time = 0
                
                if current_time - main.last_print_time >= 1.0:
                    print(f"[{time.strftime('%H:%M:%S')}] ì‚¬ëŒì´ ê°ì§€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                    print("-" * 40)
                    main.last_print_time = current_time
            
            # í”„ë ˆì„ ë²ˆí˜¸ í‘œì‹œ (ë””ë²„ê¹…ìš©)
            frame_text = f"í”„ë ˆì„: {frame_count}"
            image = put_korean_text(image, frame_text, (w-200, 30), 16, (255, 255, 255))
            
            # ì‚¬ìš©ë²• ì•ˆë‚´
            guide_text = "ESC: ì¢…ë£Œ"
            image = put_korean_text(image, guide_text, (w-150, h-30), 16, (255, 255, 255))
            
            # í™”ë©´ì— ì¶œë ¥
            try:
                cv2.imshow(window_name, image)
            except Exception as e:
                print(f"í™”ë©´ í‘œì‹œ ì˜¤ë¥˜: {e}")
                break
            
            # ESC í‚¤ë¡œ ì¢…ë£Œ
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC
                break
            elif key == ord('q'):  # q í‚¤
                break
    
    # ì •ë¦¬
    if cap:
        cap.release()
    cv2.destroyAllWindows()
    print("ì‹œìŠ¤í…œì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 