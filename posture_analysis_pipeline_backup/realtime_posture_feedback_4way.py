#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì‹¤ì‹œê°„ ìì„¸ ë“±ê¸‰ í”¼ë“œë°± ì‹œìŠ¤í…œ (4way ëª¨ë¸ í†µí•©)

python3 realtime_posture_feedback_4way.py --csv data/results/side_analysis_p1/side_angle_analysis.csv

ì›¹ìº ìœ¼ë¡œ ì‹¤ì‹œê°„ ì˜ìƒì„ ë°›ì•„ì„œ ìì„¸ë¥¼ ë¶„ì„í•˜ê³  ë“±ê¸‰(A/B/C)ê³¼ í”¼ë“œë°±ì„ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
4way ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¸¡ë©´ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³ , ìì„¸ ë“±ê¸‰ì„ ë§¤ê¹ë‹ˆë‹¤.
"""

import os
import sys

import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
from pathlib import Path
import argparse
import sys
from PIL import Image, ImageDraw, ImageFont
import pickle
import time
import math

# ìì²´ ëª¨ë“ˆ import
sys.path.append('side_angle_analysis_folder')
from posture_grade_classifier import PostureGradeClassifier


class RealTimePoseClassifier4Way:
    def __init__(self, model_path='pose_classifier_4way_model.pkl'):
        self.model = None
        self.scaler = None
        self.is_trained = False
        self.classes = ['ì •ë©´', 'ì¢Œì¸¡ë©´', 'ìš°ì¸¡ë©´']
        self.load_model(model_path)
        
    def normalize_coordinates(self, landmarks):
        """ì–´ê¹¨ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ì¢Œí‘œ ì •ê·œí™”"""
        normalized = []
        
        # ì–´ê¹¨ ì¤‘ì‹¬ì  ê³„ì‚° (ëœë“œë§ˆí¬ 11, 12)
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_center_x = (landmarks[11] + landmarks[12]) / 2
            shoulder_center_y = (landmarks[11+1] + landmarks[12+1]) / 2
        else:
            shoulder_center_x, shoulder_center_y = 0, 0
            
        # ì–´ê¹¨ ë„ˆë¹„ë¡œ ì •ê·œí™”
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_width = abs(landmarks[11] - landmarks[12])
        else:
            shoulder_width = 1.0
            
        # ê° ëœë“œë§ˆí¬ë¥¼ ì–´ê¹¨ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
        for i in range(0, len(landmarks), 2):
            if landmarks[i] != -1 and landmarks[i+1] != -1:
                norm_x = (landmarks[i] - shoulder_center_x) / max(shoulder_width, 0.001)
                norm_y = (landmarks[i+1] - shoulder_center_y) / max(shoulder_width, 0.001)
                normalized.extend([norm_x, norm_y])
            else:
                normalized.extend([0, 0])
                
        return normalized
    
    def calculate_angles(self, landmarks):
        """ì£¼ìš” ê°ë„ ê³„ì‚°"""
        angles = []
        
        # ëª©-ì–´ê¹¨-íŒ”ê¿ˆì¹˜ ê°ë„ (ëœë“œë§ˆí¬ 0-11-12)
        if landmarks[0] != -1 and landmarks[11] != -1 and landmarks[12] != -1:
            dx1 = landmarks[11] - landmarks[0]
            dy1 = landmarks[11+1] - landmarks[0+1]
            dx2 = landmarks[12] - landmarks[11]
            dy2 = landmarks[12+1] - landmarks[11+1]
            
            dot_product = dx1*dx2 + dy1*dy2
            mag1 = np.sqrt(dx1*dx1 + dy1*dy1)
            mag2 = np.sqrt(dx2*dx2 + dy2*dy2)
            
            if mag1 > 0 and mag2 > 0:
                cos_angle = dot_product / (mag1 * mag2)
                cos_angle = np.clip(cos_angle, -1.0, 1.0)
                angle = np.arccos(cos_angle)
                angles.append(np.degrees(angle))
            else:
                angles.append(0)
        else:
            angles.append(0)
        
        return angles
    
    def extract_features(self, landmarks):
        """íŠ¹ì§• ì¶”ì¶œ (4way ëª¨ë¸ê³¼ ë™ì¼í•œ êµ¬ì¡°)"""
        features = []
        
        # 1. ì •ê·œí™”ëœ ì¢Œí‘œ (ì¤‘ìš”í•œ ë¶€ìœ„ë§Œ ì„ íƒ)
        normalized_coords = self.normalize_coordinates(landmarks)
        
        # ë¨¸ë¦¬, ëª©, ì–´ê¹¨ ë¶€ìœ„ë§Œ ì„ íƒ (ëœë“œë§ˆí¬ 0-12)
        important_landmarks = []
        for i in range(0, 26, 2):  # 0-12ë²ˆ ëœë“œë§ˆí¬ë§Œ
            important_landmarks.extend([normalized_coords[i], normalized_coords[i+1]])
        
        features.extend(important_landmarks)
        
        # 2. ê°ë„ íŠ¹ì§•
        angles = self.calculate_angles(landmarks)
        features.extend(angles)
        
        # 3. ì–´ê¹¨ ë¹„ìœ¨
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_width = abs(landmarks[11] - landmarks[12])
            shoulder_height = abs(landmarks[11+1] - landmarks[12+1])
            shoulder_ratio = shoulder_width / max(shoulder_height, 0.001)
            features.append(shoulder_ratio)
        else:
            features.append(1.0)
        
        # 4. ëŒ€ì¹­ì„± íŠ¹ì§•
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_symmetry = abs(landmarks[11+1] - landmarks[12+1])
            features.append(shoulder_symmetry)
        else:
            features.append(0)
        
        # 5. ì–´ê¹¨ ë°©í–¥ íŠ¹ì§• (ì¢Œì¸¡ë©´/ìš°ì¸¡ë©´ êµ¬ë¶„ìš©) - 4way ëª¨ë¸ê³¼ ë™ì¼
        if landmarks[11] != -1 and landmarks[12] != -1:
            # ì™¼ìª½ ì–´ê¹¨ê°€ ë” ìœ„ì— ìˆëŠ”ì§€ (ì¢Œì¸¡ë©´ íŠ¹ì§•)
            left_shoulder_higher = landmarks[11+1] - landmarks[12+1]
            features.append(left_shoulder_higher)
            
            # ì–´ê¹¨ì˜ xì¶• ì°¨ì´ (ì¸¡ë©´ êµ¬ë¶„ìš©)
            shoulder_x_diff = landmarks[11] - landmarks[12]
            features.append(shoulder_x_diff)
        else:
            features.extend([0, 0])
        
        return features
    
    def load_model(self, model_path):
        """4way ëª¨ë¸ ë¡œë“œ"""
        try:
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.is_trained = model_data['is_trained']
            self.classes = model_data.get('classes', ['ì •ë©´', 'ì¢Œì¸¡ë©´', 'ìš°ì¸¡ë©´'])
            
            print(f"4way ëª¨ë¸ì´ {model_path}ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"í´ë˜ìŠ¤: {self.classes}")
        except Exception as e:
            print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ë¨¼ì € 4way ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
            self.is_trained = False
    
    def predict(self, landmarks):
        """ì‹¤ì‹œê°„ ì˜ˆì¸¡ (3í´ë˜ìŠ¤)"""
        if not self.is_trained or self.model is None or self.scaler is None:
            return None, None
        
        try:
            features = self.extract_features(landmarks)
            features_scaled = self.scaler.transform([features])
            
            prediction = self.model.predict(features_scaled)[0]
            probability = self.model.predict_proba(features_scaled)[0]
            
            return prediction, probability
        except Exception as e:
            print(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return None, None


class PostureAnalyzer:
    def __init__(self):
        self.mp_pose = mp.solutions.pose

    def calculate_angle(self, a, b, c):
        """ì„¸ ì ìœ¼ë¡œ ê°ë„ ê³„ì‚°"""
        a_pt = np.array([a.x, a.y]) if not isinstance(a, np.ndarray) else a
        b_pt = np.array([b.x, b.y]) if not isinstance(b, np.ndarray) else b
        c_pt = np.array([c.x, c.y]) if not isinstance(c, np.ndarray) else c

        ba = a_pt - b_pt
        bc = c_pt - b_pt

        cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
        angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))
        return np.degrees(angle)

    def analyze_turtle_neck_detailed(self, landmarks):
        """ëª© ìì„¸ ìƒì„¸ ë¶„ì„"""
        left_ear = landmarks[self.mp_pose.PoseLandmark.LEFT_EAR]
        right_ear = landmarks[self.mp_pose.PoseLandmark.RIGHT_EAR]
        left_shoulder = landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER]
        right_shoulder = landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER]
        
        # ëª© ì¤‘ì‹¬ì  ê³„ì‚°
        neck_top_x = (left_ear.x + right_ear.x) / 2
        neck_top_y = (left_ear.y + right_ear.y) / 2
        shoulder_center_x = (left_shoulder.x + right_shoulder.x) / 2
        shoulder_center_y = (left_shoulder.y + right_shoulder.y) / 2
        
        # ëª© ê°ë„ ê³„ì‚°
        ear_center = np.array([neck_top_x, neck_top_y])
        shoulder_center = np.array([shoulder_center_x, shoulder_center_y])
        vertical = np.array([shoulder_center[0], ear_center[1]])
        neck_angle = self.calculate_angle(ear_center, shoulder_center, vertical)
        
        # ë“±ê¸‰ ë¶„ë¥˜
        grade, desc = self.grade_neck_posture(neck_angle)
        
        # ìˆ˜ì§ ì´íƒˆë„ ê³„ì‚°
        vertical_deviation = abs(neck_top_x - shoulder_center_x)
        
        return {
            'neck_angle': neck_angle,
            'grade': grade,
            'grade_description': desc,
            'vertical_deviation': vertical_deviation,
            'neck_top': (neck_top_x, neck_top_y),
            'shoulder_center': (shoulder_center_x, shoulder_center_y)
        }

    def grade_neck_posture(self, neck_angle):
        """ëª© ìì„¸ ë“±ê¸‰ ë¶„ë¥˜"""
        if neck_angle <= 5:
            return 'A', "ì™„ë²½í•œ ìì„¸"
        elif neck_angle <= 10:
            return 'B', "ì–‘í˜¸í•œ ìì„¸"
        elif neck_angle <= 15:
            return 'C', "ë³´í†µ ìì„¸"
        else:
            return 'D', "ë‚˜ìœ ìì„¸"

    def get_comprehensive_grade(self, landmarks):
        """ì¢…í•© ìì„¸ ë“±ê¸‰ ê³„ì‚°"""
        neck_analysis = self.analyze_turtle_neck_detailed(landmarks)
        
        # ëª© ìì„¸ ì ìˆ˜ ê³„ì‚°
        neck_score = self.get_neck_score(neck_analysis['neck_angle'])
        
        # ì¢…í•© ì ìˆ˜ (ëª© ìì„¸ì— ì§‘ì¤‘)
        total_score = neck_score
        
        # ì¢…í•© ë“±ê¸‰ ê²°ì •
        if total_score >= 90:
            grade = 'A'
        elif total_score >= 80:
            grade = 'B'
        elif total_score >= 70:
            grade = 'C'
        else:
            grade = 'D'
        
        return {
            'total_grade': grade,
            'total_score': total_score,
            'neck_score': neck_score,
            'details': {
                'neck': neck_analysis
            }
        }

    def get_neck_score(self, neck_angle):
        """ëª© ìì„¸ ì ìˆ˜ ê³„ì‚°"""
        if neck_angle <= 5:
            return 100
        elif neck_angle <= 10:
            return 90
        elif neck_angle <= 15:
            return 80
        elif neck_angle <= 20:
            return 70
        else:
            return 60


def landmarks_to_array(landmarks):
    """MediaPipe landmarksë¥¼ ë°°ì—´ë¡œ ë³€í™˜"""
    landmarks_array = []
    for landmark in landmarks:
        landmarks_array.extend([landmark.x, landmark.y])
    return landmarks_array


def put_korean_text(img, text, position, font_size=32, color=(255, 255, 255), thickness=2):
    """
    í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ëŠ” í•¨ìˆ˜
    NanumGothic í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        # NanumGothic í°íŠ¸ ê²½ë¡œ (ì‹œìŠ¤í…œì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
        font_paths = [
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
            "/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf",
            "/System/Library/Fonts/NanumGothic.ttf",  # macOS
            "C:/Windows/Fonts/malgun.ttf",  # Windows
            "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf"  # ëŒ€ì²´ í°íŠ¸
        ]
        
        font = None
        for font_path in font_paths:
            if Path(font_path).exists():
                try:
                    font = ImageFont.truetype(font_path, font_size)
                    break
                except:
                    continue
        
        if font is None:
            # í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
            font = ImageFont.load_default()
        
        # PIL ì´ë¯¸ì§€ ìƒì„±
        pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_img)
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        draw.text(position, text, font=font, fill=color[::-1])  # BGR to RGB
        
        # OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜
        return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
    
    except Exception as e:
        print(f"í•œê¸€ í…ìŠ¤íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ OpenCV í…ìŠ¤íŠ¸ ì‚¬ìš©
        cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX, 
                   font_size/32, color, thickness)
        return img


def calculate_grade_thresholds(csv_path: str):
    """CSV íŒŒì¼ì—ì„œ ë“±ê¸‰ ë¶„ë¥˜ ê¸°ì¤€ê°’ë“¤ì„ ê³„ì‚°"""
    try:
        df = pd.read_csv(csv_path)
        cva_angles = df['cva_angle'].dropna().values
        
        if len(cva_angles) == 0:
            return None
        
        # ì ˆëŒ“ê°’ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
        abs_angles = np.abs(cva_angles)
        min_abs = abs_angles.min()
        max_abs = abs_angles.max()
        angle_range = max_abs - min_abs
        
        # 10ë‹¨ê³„ë¡œ ë‚˜ëˆ„ê¸°
        if angle_range == 0:
            stages = np.ones_like(abs_angles, dtype=int)
        else:
            stages = ((abs_angles - min_abs) / angle_range * 9 + 1).astype(int)
            stages = np.clip(stages, 1, 10)
        
        # 1ë‹¨ê³„ì— í•´ë‹¹í•˜ëŠ” ê°ë„ë“¤
        stage1_angles = abs_angles[stages == 1]
        stage1_threshold = np.percentile(stage1_angles, 50) if len(stage1_angles) > 0 else min_abs
        
        return {
            'min_abs': min_abs,
            'max_abs': max_abs,
            'stage1_threshold': stage1_threshold
        }
    except Exception as e:
        print(f"âŒ ê¸°ì¤€ê°’ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return None


def calculate_cva_angle(landmarks, side='right'):
    """
    Mediapipe ëœë“œë§ˆí¬ì—ì„œ CVA ê°ë„ ê³„ì‚° (ìˆ˜ì •ëœ ë²„ì „)
    
    CVA = Cervical Vertebral Angle
    ëª©-ì–´ê¹¨ ì„ ê³¼ ìˆ˜ì§ì„  ì‚¬ì´ì˜ ê°ë„
    
    Args:
        landmarks: Mediapipe pose landmarks
        side: ì¸¡ë©´ ('right' ë˜ëŠ” 'left')
    
    Returns:
        CVA ê°ë„ (ë„)
    """
    if side == 'right':
        # ì˜¤ë¥¸ìª½ ì¸¡ë©´: ê·€(8), ì–´ê¹¨(12)
        ear = np.array([landmarks[8].x, landmarks[8].y])
        shoulder = np.array([landmarks[12].x, landmarks[12].y])
    else:
        # ì™¼ìª½ ì¸¡ë©´: ê·€(7), ì–´ê¹¨(11)
        ear = np.array([landmarks[7].x, landmarks[7].y])
        shoulder = np.array([landmarks[11].x, landmarks[11].y])
    
    # ëª©-ì–´ê¹¨ ë²¡í„° (ì–´ê¹¨ì—ì„œ ê·€ë¡œ)
    neck_vector = ear - shoulder
    
    # ìˆ˜ì§ ë²¡í„° (ìœ„ìª½ ë°©í–¥)
    vertical_vector = np.array([0, -1])  # yì¶• ìŒì˜ ë°©í–¥ (í™”ë©´ì—ì„œ ìœ„ìª½)
    
    # ê°ë„ ê³„ì‚°
    dot_product = np.dot(neck_vector, vertical_vector)
    norm_neck = np.linalg.norm(neck_vector)
    norm_vertical = np.linalg.norm(vertical_vector)
    
    if norm_neck == 0:
        return 0.0
    
    cos_angle = np.clip(dot_product / (norm_neck * norm_vertical), -1.0, 1.0)
    angle_rad = np.arccos(cos_angle)
    angle_deg = np.degrees(angle_rad)
    
    # ëª©ì´ ì•ìœ¼ë¡œ ê¸°ìš¸ì–´ì§€ë©´ ì–‘ìˆ˜, ë’¤ë¡œ ê¸°ìš¸ì–´ì§€ë©´ ìŒìˆ˜
    # x ì¢Œí‘œë¡œ ë°©í–¥ íŒë‹¨ (ê·€ê°€ ì–´ê¹¨ë³´ë‹¤ ì•ì— ìˆìœ¼ë©´ ì–‘ìˆ˜)
    if neck_vector[0] > 0:  # ê·€ê°€ ì–´ê¹¨ë³´ë‹¤ ì˜¤ë¥¸ìª½(ì•ìª½)ì— ìˆìœ¼ë©´
        angle_deg = angle_deg
    else:
        angle_deg = -angle_deg
    
    return angle_deg


def get_feedback_message(grade: str, cva_angle: float) -> tuple:
    """ë“±ê¸‰ì— ë”°ë¥¸ í”¼ë“œë°± ë©”ì‹œì§€ì™€ ìƒ‰ìƒ ë°˜í™˜"""
    if grade == 'A':
        message = "ìµœê³ ! ë°”ë¥¸ ìì„¸ì…ë‹ˆë‹¤. ğŸ‘"
        color = (0, 255, 0)  # ì´ˆë¡ìƒ‰
    elif grade == 'B':
        message = "ë³´í†µ ìì„¸ì…ë‹ˆë‹¤. ì¡°ê¸ˆë§Œ ë” ì‹ ê²½ì¨ë³´ì„¸ìš”! ğŸ’ª"
        color = (0, 255, 255)  # ë…¸ë€ìƒ‰
    else:  # C
        message = "ìì„¸ê°€ ë§ì´ ë¬´ë„ˆì¡Œì–´ìš”! ë°”ë¡œì¡ìœ¼ì„¸ìš”! âš ï¸"
        color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰
    
    return message, color


def detect_side_with_4way_model(landmarks, classifier):
    """
    4way ëª¨ë¸ì„ ì‚¬ìš©í•œ ì¸¡ë©´ ê°ì§€
    """
    try:
        # ëœë“œë§ˆí¬ë¥¼ ë°°ì—´ë¡œ ë³€í™˜
        landmarks_array = landmarks_to_array(landmarks)
        
        # 4way ëª¨ë¸ë¡œ ì˜ˆì¸¡
        prediction, probability = classifier.predict(landmarks_array)
        
        if prediction is not None and probability is not None:
            # ì˜ˆì¸¡ ê²°ê³¼ì— ë”°ë¥¸ ì¸¡ë©´ ê²°ì •
            if prediction == 0:  # ì •ë©´
                return None  # ì •ë©´ì¼ ë•ŒëŠ” None ë°˜í™˜
            elif prediction == 1:  # ì¢Œì¸¡ë©´
                return 'left'
            elif prediction == 2:  # ìš°ì¸¡ë©´
                return 'right'
            else:
                return 'right'  # ê¸°ë³¸ê°’
        else:
            # ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
            return 'right'
            
    except Exception as e:
        print(f"4way ëª¨ë¸ ì¸¡ë©´ ê°ì§€ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ê°€ì‹œì„± ê¸°ë°˜ ê°ì§€ë¡œ fallback
        right_ear_visibility = landmarks[8].visibility
        left_ear_visibility = landmarks[7].visibility
        right_shoulder_visibility = landmarks[12].visibility
        left_shoulder_visibility = landmarks[11].visibility
        
        right_score = right_ear_visibility + right_shoulder_visibility
        left_score = left_ear_visibility + left_shoulder_visibility
        
        if right_score > left_score:
            return 'right'
        else:
            return 'left'


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ì‹¤ì‹œê°„ ìì„¸ ë“±ê¸‰ í”¼ë“œë°± ì‹œìŠ¤í…œ (4way ëª¨ë¸ í†µí•©)')
    parser.add_argument('--right-csv', '-r', 
                       help='ì˜¤ë¥¸ìª½ ì¸¡ë©´ ê¸°ì¤€ ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--left-csv', '-l', 
                       help='ì™¼ìª½ ì¸¡ë©´ ê¸°ì¤€ ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--csv', '-c', 
                       help='ê¸°ì¤€ ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œ (ì¸¡ë©´ë³„ë¡œ ìë™ ì„ íƒë¨)')
    parser.add_argument('--side', '-s', choices=['right', 'left'], default='right',
                       help='ì¸¡ë©´ (right ë˜ëŠ” left)')
    parser.add_argument('--camera', type=int, default=0,
                       help='ì¹´ë©”ë¼ ì¸ë±ìŠ¤ (ê¸°ë³¸ê°’: 0)')
    parser.add_argument('--model', '-m', default='pose_classifier_4way_model.pkl',
                       help='4way ëª¨ë¸ íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    # 4way ëª¨ë¸ ì´ˆê¸°í™”
    print(f"ğŸ¯ 4way ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤...")
    classifier = RealTimePoseClassifier4Way(args.model)
    
    if not classifier.is_trained:
        print("âŒ 4way ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        return 1
    
    # ì¸¡ë©´ë³„ CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
    if args.right_csv and args.left_csv:
        # ë‘ CSV íŒŒì¼ì´ ì§ì ‘ ì…ë ¥ëœ ê²½ìš°
        right_csv_paths = [args.right_csv]
        left_csv_paths = [args.left_csv]
        print(f"ğŸ¯ ì§ì ‘ ì…ë ¥ëœ ì¸¡ë©´ë³„ CSV íŒŒì¼:")
        print(f"   ì˜¤ë¥¸ìª½: {args.right_csv}")
        print(f"   ì™¼ìª½: {args.left_csv}")
    elif args.csv:
        # í•˜ë‚˜ì˜ CSV íŒŒì¼ì´ ì…ë ¥ëœ ê²½ìš° (ê¸°ì¡´ ë°©ì‹)
        csv_base_path = Path(args.csv)
        
        # ì¸¡ë©´ë³„ë¡œ ë‹¤ë¥¸ CSV íŒŒì¼ ì‚¬ìš©
        if 'right' in str(csv_base_path) or 'p1' in str(csv_base_path):
            # ì˜¤ë¥¸ìª½ ì¸¡ë©´ìš© CSV íŒŒì¼ë“¤
            right_csv_paths = [
                "data/results/side_analysis_p1/side_angle_analysis.csv",
                "data/posture_grades/posture_grades_right.csv",
                "data/landmarks_p1/raw_landmarks.csv"
            ]
            left_csv_paths = [
                "data/results/side_analysis_p2/side_angle_analysis.csv", 
                "data/posture_grades/posture_grades_left.csv",
                "data/landmarks_p2/raw_landmarks.csv"
            ]
        else:
            # ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
            right_csv_paths = [str(csv_base_path)]
            left_csv_paths = [str(csv_base_path)]
    else:
        print("âŒ CSV íŒŒì¼ì„ ì§€ì •í•´ì£¼ì„¸ìš”.")
        print("   ë°©ë²• 1: --right-csvì™€ --left-csvë¡œ ê°ê° ì§€ì •")
        print("   ë°©ë²• 2: --csvë¡œ í•˜ë‚˜ë§Œ ì§€ì • (ìë™ìœ¼ë¡œ ì¸¡ë©´ë³„ íŒŒì¼ ì°¾ê¸°)")
        return 1
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ CSV íŒŒì¼ ì°¾ê¸°
    def find_available_csv(csv_paths):
        for path in csv_paths:
            if Path(path).exists():
                return path
        return None
    
    right_csv = find_available_csv(right_csv_paths)
    left_csv = find_available_csv(left_csv_paths)
    
    if not right_csv or not left_csv:
        print(f"âŒ ì¸¡ë©´ë³„ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ì˜¤ë¥¸ìª½: {right_csv}")
        print(f"   ì™¼ìª½: {left_csv}")
        return 1
    
    print(f"ğŸ“Š ì¸¡ë©´ë³„ ê¸°ì¤€ ë°ì´í„°:")
    print(f"   ì˜¤ë¥¸ìª½: {right_csv}")
    print(f"   ì™¼ìª½: {left_csv}")
    
    # ì¸¡ë©´ë³„ ê¸°ì¤€ê°’ ê³„ì‚°
    print(f"\nğŸ“Š ê¸°ì¤€ê°’ì„ ê³„ì‚°í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
    right_thresholds = calculate_grade_thresholds(right_csv)
    left_thresholds = calculate_grade_thresholds(left_csv)
    
    if right_thresholds is None or left_thresholds is None:
        print("âŒ ê¸°ì¤€ê°’ ê³„ì‚° ì‹¤íŒ¨")
        return 1
    
    print(f"âœ… ê¸°ì¤€ê°’ ê³„ì‚° ì™„ë£Œ!")
    print(f"  ì˜¤ë¥¸ìª½ - min_abs: {right_thresholds['min_abs']:.2f}, max_abs: {right_thresholds['max_abs']:.2f}")
    print(f"  ì™¼ìª½ - min_abs: {left_thresholds['min_abs']:.2f}, max_abs: {left_thresholds['max_abs']:.2f}")
    
    # ìì„¸ ë¶„ì„ê¸° ì´ˆê¸°í™”
    posture_analyzer = PostureAnalyzer()
    
    # ë“±ê¸‰ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
    posture_classifier = PostureGradeClassifier()
    
    # Mediapipe ì´ˆê¸°í™”
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(
        static_image_mode=False,
        model_complexity=1,
        smooth_landmarks=True,
        enable_segmentation=False,
        smooth_segmentation=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    )
    
    # ì¹´ë©”ë¼ ì´ˆê¸°í™”
    cap = cv2.VideoCapture(args.camera)
    if not cap.isOpened():
        print(f"âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ì¸ë±ìŠ¤ {args.camera}ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return 1

    # OpenCV ì°½ ëª…ì‹œì ìœ¼ë¡œ ìƒì„±
    cv2.namedWindow('Real-time Posture Feedback (4way í†µí•©)', cv2.WINDOW_NORMAL)
    
    print(f"\nğŸ¥ ì¹´ë©”ë¼ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ’¡ ESC í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
    
    frame_count = 0
    grade_history = []
    pose_history = []
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            print("âŒ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break
        
        # í”„ë ˆì„ì„ RGBë¡œ ë³€í™˜
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image)
        
        # í™”ë©´ì— ê¸°ë³¸ ì •ë³´ í‘œì‹œ
        frame = put_korean_text(frame, f"Camera: {args.camera} | 4way ëª¨ë¸ í†µí•©", 
                               (10, 30), font_size=24, color=(255, 255, 255))
        
        if results.pose_landmarks:
            # 4way ëª¨ë¸ì„ ì‚¬ìš©í•œ ìë™ ì¸¡ë©´ ê°ì§€ (ë§¤ í”„ë ˆì„ë§ˆë‹¤)
            detected_side = detect_side_with_4way_model(results.pose_landmarks.landmark, classifier)
            if frame_count == 0:
                print(f"ğŸ¯ 4way ëª¨ë¸ë¡œ ê°ì§€ëœ ì¸¡ë©´: {detected_side}")
            elif frame_count % 30 == 0:  # 30í”„ë ˆì„ë§ˆë‹¤ ì¸¡ë©´ ì •ë³´ ì¶œë ¥
                print(f"ğŸ¯ ì¸¡ë©´ ê°ì§€: {detected_side}")
            
            # ì¸¡ë©´ì— ë”°ë¥¸ ê¸°ì¤€ê°’ ì„ íƒ
            if detected_side is not None:
                current_thresholds = right_thresholds if detected_side == 'right' else left_thresholds
                
                # CVA ê°ë„ ê³„ì‚° (ì¸¡ë©´ì¼ ë•Œë§Œ)
                cva_angle = calculate_cva_angle(results.pose_landmarks.landmark, detected_side)
                
                # ê°ë„ ë²”ìœ„ ì œí•œ (ë¹„ì •ìƒì ì¸ ê°’ í•„í„°ë§)
                if abs(cva_angle) > 90:
                    cva_angle = np.clip(cva_angle, -90, 90)
                
                # ë“±ê¸‰ ë¶„ë¥˜ (ì¸¡ë©´ë³„ ê¸°ì¤€ê°’ ì‚¬ìš©)
                grade = posture_classifier.get_grade_for_angle(
                    cva_angle, 
                    current_thresholds['min_abs'], 
                    current_thresholds['max_abs'], 
                    current_thresholds['stage1_threshold']
                )
            else:
                # ì •ë©´ì¼ ë•ŒëŠ” CVA ê°ë„ ê³„ì‚°í•˜ì§€ ì•ŠìŒ
                cva_angle = None
                grade = None
            
            # ìì„¸ ë“±ê¸‰ ë¶„ì„ (PostureAnalyzer ì‚¬ìš©)
            comprehensive_grade = posture_analyzer.get_comprehensive_grade(results.pose_landmarks.landmark)
            posture_grade = comprehensive_grade['total_grade']
            posture_score = comprehensive_grade['total_score']
            
            # ë””ë²„ê¹… ì •ë³´ (ì²˜ìŒ 5í”„ë ˆì„ì—ì„œë§Œ)
            if frame_count < 5:
                if detected_side == 'right':
                    ear = results.pose_landmarks.landmark[8]
                    shoulder = results.pose_landmarks.landmark[12]
                else:
                    ear = results.pose_landmarks.landmark[7]
                    shoulder = results.pose_landmarks.landmark[11]
                
                print(f"ğŸ” í”„ë ˆì„ {frame_count}: ì¸¡ë©´={detected_side}, ê°ë„={cva_angle:.1f}Â°")
                print(f"   ê·€: ({ear.x:.3f}, {ear.y:.3f}), ê°€ì‹œì„±: {ear.visibility:.3f}")
                print(f"   ì–´ê¹¨: ({shoulder.x:.3f}, {shoulder.y:.3f}), ê°€ì‹œì„±: {shoulder.visibility:.3f}")
                print(f"   ì‚¬ìš© ê¸°ì¤€ê°’: {current_thresholds['min_abs']:.2f} ~ {current_thresholds['max_abs']:.2f}")
                print(f"   ìì„¸ ë“±ê¸‰: {posture_grade} (ì ìˆ˜: {posture_score:.1f})")
            
            # ë“±ê¸‰ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (ìµœê·¼ 10í”„ë ˆì„)
            if grade is not None:
                grade_history.append(grade)
                if len(grade_history) > 10:
                    grade_history.pop(0)
            
            # ìì„¸ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (ìµœê·¼ 10í”„ë ˆì„)
            pose_history.append(posture_grade)
            if len(pose_history) > 10:
                pose_history.pop(0)
            
            # ì•ˆì •í™”ëœ ë“±ê¸‰ (ìµœê·¼ 5í”„ë ˆì„ ì¤‘ ê°€ì¥ ë§ì€ ë“±ê¸‰)
            if len(grade_history) >= 5 and grade is not None:
                stable_grade = max(set(grade_history[-5:]), key=grade_history[-5:].count)
            else:
                stable_grade = grade
            
            # ì•ˆì •í™”ëœ ìì„¸ ë“±ê¸‰
            if len(pose_history) >= 5:
                stable_posture_grade = max(set(pose_history[-5:]), key=pose_history[-5:].count)
            else:
                stable_posture_grade = posture_grade
            
            # í”¼ë“œë°± ë©”ì‹œì§€ì™€ ìƒ‰ìƒ (ì¸¡ë©´ì¼ ë•Œë§Œ)
            if stable_grade is not None and cva_angle is not None:
                message, color = get_feedback_message(stable_grade, cva_angle)
            else:
                # ì •ë©´ì¼ ë•ŒëŠ” ìì„¸ ë“±ê¸‰ë§Œ í‘œì‹œ
                message = "ì •ë©´ ìì„¸ ë¶„ì„ ì¤‘..."
                color = (128, 128, 128)  # íšŒìƒ‰
            
            # í™”ë©´ì— ì •ë³´ í‘œì‹œ
            # ë“±ê¸‰ í‘œì‹œ (ì¸¡ë©´ì¼ ë•Œë§Œ)
            if stable_grade is not None:
                frame = put_korean_text(frame, f"Grade: {stable_grade}", 
                                       (30, 80), font_size=48, color=color)
            else:
                frame = put_korean_text(frame, "Front View", 
                                       (30, 80), font_size=48, color=(128, 128, 128))
            
            # CVA ê°ë„ í‘œì‹œ (ì¸¡ë©´ì¼ ë•Œë§Œ)
            if cva_angle is not None:
                frame = put_korean_text(frame, f"CVA: {cva_angle:.1f}Â°", 
                                       (30, 130), font_size=32, color=(255, 255, 255))
            # ì •ë©´ì¼ ë•ŒëŠ” CVA ê°ë„ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŒ
            
            # ìì„¸ ë“±ê¸‰ í‘œì‹œ (PostureAnalyzer ê²°ê³¼)
            # frame = put_korean_text(frame, f"Posture Grade: {stable_posture_grade} (ì ìˆ˜: {posture_score:.1f})", 
            #                        (30, 190), font_size=24, color=posture_color)
            
            # í”¼ë“œë°± ë©”ì‹œì§€ í‘œì‹œ
            frame = put_korean_text(frame, message, 
                                   (30, 220), font_size=28, color=color)
            
            # í”„ë ˆì„ ì¹´ìš´íŠ¸ í‘œì‹œ
            frame_count += 1
            frame = put_korean_text(frame, f"Frame: {frame_count}", 
                                   (30, 250), font_size=20, color=(255, 255, 255))
            
        else:
            # ëœë“œë§ˆí¬ê°€ ê°ì§€ë˜ì§€ ì•Šì„ ë•Œ
            frame = put_korean_text(frame, "No pose detected", 
                                   (30, 80), font_size=32, color=(0, 0, 255))
            frame = put_korean_text(frame, "Please stand in front of the camera", 
                                   (30, 120), font_size=24, color=(255, 255, 255))
        
        # í™”ë©´ í‘œì‹œ
        cv2.imshow('Real-time Posture Feedback (4way í†µí•©)', frame)
        
        # ESC í‚¤ë¡œ ì¢…ë£Œ
        if cv2.waitKey(1) & 0xFF == 27:
            break
    
    # ì •ë¦¬
    cap.release()
    cv2.destroyAllWindows()
    print(f"\nğŸ‰ ì‹¤ì‹œê°„ ìì„¸ ë¶„ì„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“Š ì´ ë¶„ì„ í”„ë ˆì„: {frame_count}")
    
    return 0


if __name__ == "__main__":
    exit(main()) 