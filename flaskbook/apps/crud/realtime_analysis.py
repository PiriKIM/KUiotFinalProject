#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì‹¤ì‹œê°„ ìì„¸ ë¶„ì„ Flask ë¼ìš°íŠ¸
ESP32-CAMì—ì„œ ì „ì†¡ëœ ì˜ìƒì„ ë°›ì•„ì„œ ì‹¤ì‹œê°„ ìì„¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import cv2
import numpy as np
import mediapipe as mp
import pickle
import pandas as pd
from pathlib import Path
import threading
import time
from datetime import datetime
from flask import Blueprint, request, jsonify, render_template, Response, current_app
from flask_login import login_required, current_user
from apps.app import db
from apps.crud.models import RealtimePostureRecord
import warnings
import subprocess
import os
warnings.filterwarnings('ignore')

# ìì²´ ëª¨ë“ˆ import
import sys
sys.path.append('/home/piri/KUiotFinalProject/merge_mp/ml_models')
from posture_grade_classifier import PostureGradeClassifier

realtime_bp = Blueprint('realtime', __name__)

# ì „ì—­ ë³€ìˆ˜
current_frame = None
analysis_results = {}
is_analyzing = False
frame_lock = threading.Lock()

# ìŒì„± ì¬ìƒ ê´€ë ¨ ì „ì—­ ë³€ìˆ˜
last_audio_play_time = 0
AUDIO_COOLDOWN = 30  # 30ì´ˆ ì¿¨ë‹¤ìš´
AUDIO_FILE_PATH = '/home/piri/KUiotFinalProject/flaskbook/output.wav'

def play_audio_if_needed(grade):
    """Cë“±ê¸‰ ê°ì§€ ì‹œ ìŒì„± ì¬ìƒ (30ì´ˆ ì¿¨ë‹¤ìš´ ì ìš©)"""
    global last_audio_play_time
    
    if grade == 'C':
        current_time = time.time()
        
        # 30ì´ˆ ì¿¨ë‹¤ìš´ í™•ì¸
        if current_time - last_audio_play_time >= AUDIO_COOLDOWN:
            if os.path.exists(AUDIO_FILE_PATH):
                try:
                    # ì—¬ëŸ¬ ìŒì„± ì¬ìƒ ë°©ë²• ì‹œë„
                    audio_played = False
                    
                    # ë°©ë²• 1: aplay ì‚¬ìš©
                    try:
                        subprocess.Popen(['aplay', AUDIO_FILE_PATH], 
                                       stdout=subprocess.DEVNULL, 
                                       stderr=subprocess.DEVNULL)
                        audio_played = True
                        print(f"ğŸ”Š Cë“±ê¸‰ ê°ì§€! aplayë¡œ ìŒì„± ì¬ìƒë¨ (ì‹œê°„: {datetime.now().strftime('%H:%M:%S')})")
                    except Exception as e:
                        print(f"âŒ aplay ì¬ìƒ ì‹¤íŒ¨: {e}")
                    
                    # ë°©ë²• 2: paplay ì‚¬ìš© (PulseAudio)
                    if not audio_played:
                        try:
                            subprocess.Popen(['paplay', AUDIO_FILE_PATH], 
                                           stdout=subprocess.DEVNULL, 
                                           stderr=subprocess.DEVNULL)
                            audio_played = True
                            print(f"ğŸ”Š Cë“±ê¸‰ ê°ì§€! paplayë¡œ ìŒì„± ì¬ìƒë¨ (ì‹œê°„: {datetime.now().strftime('%H:%M:%S')})")
                        except Exception as e:
                            print(f"âŒ paplay ì¬ìƒ ì‹¤íŒ¨: {e}")
                    
                    # ë°©ë²• 3: ffplay ì‚¬ìš©
                    if not audio_played:
                        try:
                            subprocess.Popen(['ffplay', '-nodisp', '-autoexit', '-loglevel', 'quiet', AUDIO_FILE_PATH], 
                                           stdout=subprocess.DEVNULL, 
                                           stderr=subprocess.DEVNULL)
                            audio_played = True
                            print(f"ğŸ”Š Cë“±ê¸‰ ê°ì§€! ffplayë¡œ ìŒì„± ì¬ìƒë¨ (ì‹œê°„: {datetime.now().strftime('%H:%M:%S')})")
                        except Exception as e:
                            print(f"âŒ ffplay ì¬ìƒ ì‹¤íŒ¨: {e}")
                    
                    if audio_played:
                        last_audio_play_time = current_time
                    else:
                        print("âŒ ëª¨ë“  ìŒì„± ì¬ìƒ ë°©ë²•ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    print(f"âŒ ìŒì„± ì¬ìƒ ì¤‘ ì˜¤ë¥˜: {e}")
            else:
                print(f"âŒ ìŒì„± íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {AUDIO_FILE_PATH}")

class MLPoseClassifier:
    """ML ëª¨ë¸ ê¸°ë°˜ ìì„¸ ë¶„ë¥˜ê¸° (4way ëª¨ë¸ ì‚¬ìš©)"""
    
    def __init__(self, model_path='/home/piri/KUiotFinalProject/pose_classifier_4way_model.pkl'):
        self.model = None
        self.scaler = None
        self.is_trained = False
        self.classes = ['ì •ë©´', 'ì¢Œì¸¡ë©´', 'ìš°ì¸¡ë©´']
        self.load_model(model_path)
    
    def normalize_coordinates(self, landmarks):
        """ì–´ê¹¨ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ì¢Œí‘œ ì •ê·œí™”"""
        normalized = []
        
        # ì–´ê¹¨ ì¤‘ì‹¬ì  ê³„ì‚° (ëœë“œë§ˆí¬ 11, 12)
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_center_x = (landmarks[11] + landmarks[12]) / 2
            shoulder_center_y = (landmarks[11+1] + landmarks[12+1]) / 2
        else:
            shoulder_center_x, shoulder_center_y = 0, 0
            
        # ì–´ê¹¨ ë„ˆë¹„ë¡œ ì •ê·œí™”
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_width = abs(landmarks[11] - landmarks[12])
        else:
            shoulder_width = 1.0
            
        # ê° ëœë“œë§ˆí¬ë¥¼ ì–´ê¹¨ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
        for i in range(0, len(landmarks), 2):
            if landmarks[i] != -1 and landmarks[i+1] != -1:
                norm_x = (landmarks[i] - shoulder_center_x) / max(shoulder_width, 0.001)
                norm_y = (landmarks[i+1] - shoulder_center_y) / max(shoulder_width, 0.001)
                normalized.extend([norm_x, norm_y])
            else:
                normalized.extend([0, 0])
                
        return normalized
    
    def calculate_angles(self, landmarks):
        """ì£¼ìš” ê°ë„ ê³„ì‚°"""
        angles = []
        
        # ëª©-ì–´ê¹¨-íŒ”ê¿ˆì¹˜ ê°ë„ (ëœë“œë§ˆí¬ 0-11-12)
        if landmarks[0] != -1 and landmarks[11] != -1 and landmarks[12] != -1:
            dx1 = landmarks[11] - landmarks[0]
            dy1 = landmarks[11+1] - landmarks[0+1]
            dx2 = landmarks[12] - landmarks[11]
            dy2 = landmarks[12+1] - landmarks[11+1]
            
            dot_product = dx1*dx2 + dy1*dy2
            mag1 = np.sqrt(dx1*dx1 + dy1*dy1)
            mag2 = np.sqrt(dx2*dx2 + dy2*dy2)
            
            if mag1 > 0 and mag2 > 0:
                cos_angle = dot_product / (mag1 * mag2)
                cos_angle = np.clip(cos_angle, -1.0, 1.0)
                angle = np.arccos(cos_angle)
                angles.append(np.degrees(angle))
            else:
                angles.append(0)
        else:
            angles.append(0)
        
        return angles
    
    def extract_features(self, landmarks):
        """íŠ¹ì§• ì¶”ì¶œ (4way ëª¨ë¸ê³¼ ë™ì¼í•œ êµ¬ì¡°)"""
        features = []
        
        # 1. ì •ê·œí™”ëœ ì¢Œí‘œ (ì¤‘ìš”í•œ ë¶€ìœ„ë§Œ ì„ íƒ)
        normalized_coords = self.normalize_coordinates(landmarks)
        
        # ë¨¸ë¦¬, ëª©, ì–´ê¹¨ ë¶€ìœ„ë§Œ ì„ íƒ (ëœë“œë§ˆí¬ 0-12)
        important_landmarks = []
        for i in range(0, 26, 2):  # 0-12ë²ˆ ëœë“œë§ˆí¬ë§Œ
            important_landmarks.extend([normalized_coords[i], normalized_coords[i+1]])
        
        features.extend(important_landmarks)
        
        # 2. ê°ë„ íŠ¹ì§•
        angles = self.calculate_angles(landmarks)
        features.extend(angles)
        
        # 3. ì–´ê¹¨ ë¹„ìœ¨
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_width = abs(landmarks[11] - landmarks[12])
            shoulder_height = abs(landmarks[11+1] - landmarks[12+1])
            shoulder_ratio = shoulder_width / max(shoulder_height, 0.001)
            features.append(shoulder_ratio)
        else:
            features.append(1.0)
        
        # 4. ëŒ€ì¹­ì„± íŠ¹ì§•
        if landmarks[11] != -1 and landmarks[12] != -1:
            shoulder_symmetry = abs(landmarks[11+1] - landmarks[12+1])
            features.append(shoulder_symmetry)
        else:
            features.append(0)
        
        # 5. ì–´ê¹¨ ë°©í–¥ íŠ¹ì§• (ì¢Œì¸¡ë©´/ìš°ì¸¡ë©´ êµ¬ë¶„ìš©) - 4way ëª¨ë¸ê³¼ ë™ì¼
        if landmarks[11] != -1 and landmarks[12] != -1:
            # ì™¼ìª½ ì–´ê¹¨ê°€ ë” ìœ„ì— ìˆëŠ”ì§€ (ì¢Œì¸¡ë©´ íŠ¹ì§•)
            left_shoulder_higher = landmarks[11+1] - landmarks[12+1]
            features.append(left_shoulder_higher)
            
            # ì–´ê¹¨ì˜ xì¶• ì°¨ì´ (ì¸¡ë©´ êµ¬ë¶„ìš©)
            shoulder_x_diff = landmarks[11] - landmarks[12]
            features.append(shoulder_x_diff)
        else:
            features.extend([0, 0])
        
        return features
    
    def load_model(self, model_path):
        """4way ëª¨ë¸ ë¡œë“œ"""
        try:
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.is_trained = model_data['is_trained']
            self.classes = model_data.get('classes', ['ì •ë©´', 'ì¢Œì¸¡ë©´', 'ìš°ì¸¡ë©´'])
            
            print(f"âœ… 4way ëª¨ë¸ì´ {model_path}ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"ğŸ“Š í´ë˜ìŠ¤: {self.classes}")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ë¨¼ì € 4way ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
            self.is_trained = False
    
    def predict_pose(self, landmarks):
        """ì‹¤ì‹œê°„ ì˜ˆì¸¡ (3í´ë˜ìŠ¤)"""
        if not self.is_trained or self.model is None or self.scaler is None:
            return None, None
        
        try:
            features = self.extract_features(landmarks)
            features_scaled = self.scaler.transform([features])
            
            prediction = self.model.predict(features_scaled)[0]
            probability = self.model.predict_proba(features_scaled)[0]
            
            return prediction, probability
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return None, None


def calculate_cva_angle(landmarks, side='right'):
    """
    Mediapipe ëœë“œë§ˆí¬ì—ì„œ CVA ê°ë„ ê³„ì‚°
    """
    if side == 'right':
        # ì˜¤ë¥¸ìª½ ì¸¡ë©´: ê·€(8), ì–´ê¹¨(12)
        ear = np.array([landmarks[8].x, landmarks[8].y])
        shoulder = np.array([landmarks[12].x, landmarks[12].y])
    else:
        # ì™¼ìª½ ì¸¡ë©´: ê·€(7), ì–´ê¹¨(11)
        ear = np.array([landmarks[7].x, landmarks[7].y])
        shoulder = np.array([landmarks[11].x, landmarks[11].y])
    
    # ëª©-ì–´ê¹¨ ë²¡í„° (ì–´ê¹¨ì—ì„œ ê·€ë¡œ)
    neck_vector = ear - shoulder
    
    # ìˆ˜ì§ ë²¡í„° (ìœ„ìª½ ë°©í–¥)
    vertical_vector = np.array([0, -1])  # yì¶• ìŒì˜ ë°©í–¥ (í™”ë©´ì—ì„œ ìœ„ìª½)
    
    # ê°ë„ ê³„ì‚°
    dot_product = np.dot(neck_vector, vertical_vector)
    norm_neck = np.linalg.norm(neck_vector)
    norm_vertical = np.linalg.norm(vertical_vector)
    
    if norm_neck == 0:
        return 0.0
    
    cos_angle = np.clip(dot_product / (norm_neck * norm_vertical), -1.0, 1.0)
    angle_rad = np.arccos(cos_angle)
    angle_deg = np.degrees(angle_rad)
    
    # ëª©ì´ ì•ìœ¼ë¡œ ê¸°ìš¸ì–´ì§€ë©´ ì–‘ìˆ˜, ë’¤ë¡œ ê¸°ìš¸ì–´ì§€ë©´ ìŒìˆ˜
    if neck_vector[0] > 0:  # ê·€ê°€ ì–´ê¹¨ë³´ë‹¤ ì˜¤ë¥¸ìª½(ì•ìª½)ì— ìˆìœ¼ë©´
        angle_deg = angle_deg
    else:
        angle_deg = -angle_deg
    
    return angle_deg


def calculate_grade_thresholds(csv_path: str):
    """CSV íŒŒì¼ì—ì„œ ë“±ê¸‰ ë¶„ë¥˜ ê¸°ì¤€ê°’ë“¤ì„ ê³„ì‚°"""
    try:
        df = pd.read_csv(csv_path)
        cva_angles = df['cva_angle'].dropna().values
        
        if len(cva_angles) == 0:
            return None
        
        # ì ˆëŒ“ê°’ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
        abs_angles = np.abs(cva_angles)
        min_abs = abs_angles.min()
        max_abs = abs_angles.max()
        angle_range = max_abs - min_abs
        
        # 10ë‹¨ê³„ë¡œ ë‚˜ëˆ„ê¸°
        if angle_range == 0:
            stages = np.ones_like(abs_angles, dtype=int)
        else:
            stages = ((abs_angles - min_abs) / angle_range * 9 + 1).astype(int)
            stages = np.clip(stages, 1, 10)
        
        # 1ë‹¨ê³„ì— í•´ë‹¹í•˜ëŠ” ê°ë„ë“¤
        stage1_angles = abs_angles[stages == 1]
        stage1_threshold = np.percentile(stage1_angles, 50) if len(stage1_angles) > 0 else min_abs
        
        return {
            'min_abs': min_abs,
            'max_abs': max_abs,
            'stage1_threshold': stage1_threshold
        }
    except Exception as e:
        print(f"âŒ ê¸°ì¤€ê°’ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return None


def landmarks_to_array(landmarks):
    """MediaPipe landmarksë¥¼ ë°°ì—´ë¡œ ë³€í™˜"""
    landmarks_array = []
    for landmark in landmarks:
        landmarks_array.extend([landmark.x, landmark.y])
    return landmarks_array


def detect_side_ml(pose_classifier, landmarks):
    """ML ëª¨ë¸ì„ ì‚¬ìš©í•œ ì¸¡ë©´ ê°ì§€"""
    try:
        # ëœë“œë§ˆí¬ë¥¼ ë°°ì—´ë¡œ ë³€í™˜
        landmarks_array = landmarks_to_array(landmarks)
        
        # ML ëª¨ë¸ë¡œ ì˜ˆì¸¡
        prediction, probability = pose_classifier.predict_pose(landmarks_array)
        
        if prediction is not None and probability is not None:
            # ì˜ˆì¸¡ ê²°ê³¼ì— ë”°ë¥¸ ì¸¡ë©´ ë°˜í™˜
            if prediction == 1:  # ì •ë©´
                return 'front', probability
            elif prediction == 2:  # ì¢Œì¸¡ë©´
                return 'left', probability
            elif prediction == 3:  # ìš°ì¸¡ë©´
                return 'right', probability
            else:
                return 'unknown', probability
        else:
            return 'unknown', None
            
    except Exception as e:
        print(f"âŒ ML ì¸¡ë©´ ê°ì§€ ì˜¤ë¥˜: {e}")
        return 'unknown', None


def get_feedback_message(grade: str, cva_angle: float) -> tuple:
    """ë“±ê¸‰ì— ë”°ë¥¸ í”¼ë“œë°± ë©”ì‹œì§€ì™€ ìƒ‰ìƒ ë°˜í™˜"""
    if grade == 'A':
        message = "ìµœê³ ! ë°”ë¥¸ ìì„¸ì…ë‹ˆë‹¤. ğŸ‘"
        color = (0, 255, 0)  # ì´ˆë¡ìƒ‰
    elif grade == 'B':
        message = "ë³´í†µ ìì„¸ì…ë‹ˆë‹¤. ì¡°ê¸ˆë§Œ ë” ì‹ ê²½ì¨ë³´ì„¸ìš”! ğŸ’ª"
        color = (0, 255, 255)  # ë…¸ë€ìƒ‰
    else:  # C
        message = "ìì„¸ê°€ ë§ì´ ë¬´ë„ˆì¡Œì–´ìš”! ë°”ë¡œì¡ìœ¼ì„¸ìš”! âš ï¸"
        color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰
    
    return message, color


# ì „ì—­ ë³€ìˆ˜ë¡œ ë¶„ì„ê¸° ì´ˆê¸°í™”
pose_classifier = None
grade_classifier = None
right_thresholds = None
left_thresholds = None
mp_pose = None
pose = None

def initialize_analyzers():
    """ë¶„ì„ê¸°ë“¤ì„ ì´ˆê¸°í™”"""
    global pose_classifier, grade_classifier, right_thresholds, left_thresholds, mp_pose, pose
    
    print("ğŸ¤– ì‹¤ì‹œê°„ ìì„¸ ë¶„ì„ê¸°ë¥¼ ì´ˆê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
    
    # ML ìì„¸ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
    pose_classifier = MLPoseClassifier()
    
    if not pose_classifier.is_trained:
        print("âŒ ML ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    # ë“±ê¸‰ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
    grade_classifier = PostureGradeClassifier()
    
    # ì¸¡ë©´ë³„ ê¸°ì¤€ê°’ ê³„ì‚°
    right_csv = "/home/piri/KUiotFinalProject/merge_mp/data/right_side_angle_analysis.csv"
    left_csv = "/home/piri/KUiotFinalProject/merge_mp/data/left_side_angle_analysis.csv"
    
    right_thresholds = calculate_grade_thresholds(right_csv)
    left_thresholds = calculate_grade_thresholds(left_csv)
    
    if right_thresholds is None or left_thresholds is None:
        print("âŒ ê¸°ì¤€ê°’ ê³„ì‚° ì‹¤íŒ¨")
        return False
    
    # Mediapipe ì´ˆê¸°í™”
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(
        static_image_mode=False,
        model_complexity=1,
        smooth_landmarks=True,
        enable_segmentation=False,
        smooth_segmentation=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    )
    
    print("âœ… ì‹¤ì‹œê°„ ìì„¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ!")
    return True


def analyze_frame(frame):
    """í”„ë ˆì„ì„ ë¶„ì„í•˜ì—¬ ìì„¸ ê²°ê³¼ë¥¼ ë°˜í™˜"""
    global pose_classifier, grade_classifier, right_thresholds, left_thresholds, pose
    
    if pose_classifier is None or grade_classifier is None or pose is None:
        return None
    
    try:
        # í”„ë ˆì„ì„ RGBë¡œ ë³€í™˜
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image)
        
        if results.pose_landmarks:
            # ML ëª¨ë¸ì„ ì‚¬ìš©í•œ ì¸¡ë©´ ê°ì§€
            detected_side, probability = detect_side_ml(pose_classifier, results.pose_landmarks.landmark)
            
            # ì¸¡ë©´ì— ë”°ë¥¸ ê¸°ì¤€ê°’ ì„ íƒ
            if detected_side == 'left':
                current_thresholds = left_thresholds
                current_side = 'left'
            elif detected_side == 'right':
                current_thresholds = right_thresholds
                current_side = 'right'
            else:  # front ë˜ëŠ” unknown
                current_thresholds = right_thresholds
                current_side = 'right'
            
            # CVA ê°ë„ ê³„ì‚° (ì¸¡ë©´ì´ ìˆì„ ë•Œë§Œ)
            if detected_side in ['left', 'right']:
                cva_angle = calculate_cva_angle(results.pose_landmarks.landmark, current_side)
                
                # ê°ë„ ë²”ìœ„ ì œí•œ
                if abs(cva_angle) > 90:
                    cva_angle = np.clip(cva_angle, -90, 90)
                
                # ë“±ê¸‰ ë¶„ë¥˜
                grade = grade_classifier.get_grade_for_angle(
                    cva_angle, 
                    current_thresholds['min_abs'], 
                    current_thresholds['max_abs'], 
                    current_thresholds['stage1_threshold']
                )
                
                # Cë“±ê¸‰ ê°ì§€ ì‹œ ìŒì„± ì¬ìƒ
                play_audio_if_needed(grade)
                
                # í”¼ë“œë°± ë©”ì‹œì§€
                message, color = get_feedback_message(grade, cva_angle)
                
                # ML ì‹ ë¢°ë„
                ml_confidence = max(probability) if probability is not None else 0.0
                
                return {
                    'detected_side': detected_side,
                    'ml_confidence': ml_confidence,
                    'cva_angle': cva_angle,
                    'posture_grade': grade,
                    'feedback_message': message,
                    'min_abs_threshold': current_thresholds['min_abs'],
                    'max_abs_threshold': current_thresholds['max_abs'],
                    'stage1_threshold': current_thresholds['stage1_threshold'],
                    'pose_detected': True
                }
            else:
                return {
                    'detected_side': detected_side,
                    'ml_confidence': 0.0,
                    'cva_angle': 0.0,
                    'posture_grade': 'N/A',
                    'feedback_message': 'Front View Detected',
                    'pose_detected': True
                }
        else:
            return {
                'pose_detected': False,
                'feedback_message': 'No pose detected'
            }
            
    except Exception as e:
        print(f"âŒ í”„ë ˆì„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None


@realtime_bp.route('/esp32_stream', methods=['POST'])
def esp32_stream():
    """ESP32-CAMì—ì„œ ì „ì†¡ëœ ì˜ìƒ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ ì²˜ë¦¬"""
    global current_frame
    
    try:
        # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¡œ ë°›ê¸°
        image_data = request.get_data()
        
        # ë°”ì´íŠ¸ ë°°ì—´ì„ numpy ë°°ì—´ë¡œ ë³€í™˜
        nparr = np.frombuffer(image_data, np.uint8)
        
        # ì´ë¯¸ì§€ ë””ì½”ë”©
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if frame is not None:
            with frame_lock:
                current_frame = frame.copy()
            
            # ë¶„ì„ ê²°ê³¼ ë°˜í™˜
            return jsonify({
                'status': 'success',
                'message': 'Frame received and processed',
                'frame_size': frame.shape
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'Failed to decode image'
            }), 400
            
    except Exception as e:
        print(f"âŒ ESP32 ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@realtime_bp.route('/video_feed')
def video_feed():
    """ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì œê³µí•˜ëŠ” ì œë„ˆë ˆì´í„°"""
    def generate():
        global current_frame
        
        while True:
            with frame_lock:
                if current_frame is not None:
                    # JPEGë¡œ ì¸ì½”ë”©
                    ret, buffer = cv2.imencode('.jpg', current_frame)
                    if ret:
                        frame_data = buffer.tobytes()
                        yield (b'--frame\r\n'
                               b'Content-Type: image/jpeg\r\n\r\n' + frame_data + b'\r\n')
            
            time.sleep(0.1)  # 10 FPS
    
    return Response(generate(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')


@realtime_bp.route('/realtime_analysis')
@login_required
def realtime_analysis_page():
    """ì‹¤ì‹œê°„ ìì„¸ ë¶„ì„ í˜ì´ì§€"""
    return render_template('crud/realtime_analysis.html')


@realtime_bp.route('/start_analysis', methods=['POST'])
@login_required
def start_analysis():
    """ì‹¤ì‹œê°„ ë¶„ì„ ì‹œì‘"""
    global is_analyzing
    
    if not is_analyzing:
        is_analyzing = True
        
        # ë¶„ì„ê¸° ì´ˆê¸°í™” (ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°)
        if pose_classifier is None:
            if not initialize_analyzers():
                return jsonify({'status': 'error', 'message': 'ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨'}), 500
        
        return jsonify({'status': 'success', 'message': 'ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.'})
    else:
        return jsonify({'status': 'info', 'message': 'ì´ë¯¸ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.'})


@realtime_bp.route('/stop_analysis', methods=['POST'])
@login_required
def stop_analysis():
    """ì‹¤ì‹œê°„ ë¶„ì„ ì¤‘ì§€"""
    global is_analyzing
    is_analyzing = False
    return jsonify({'status': 'success', 'message': 'ë¶„ì„ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.'})


@realtime_bp.route('/get_analysis_result')
@login_required
def get_analysis_result():
    """í˜„ì¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜"""
    global current_frame, analysis_results, is_analyzing
    
    if not is_analyzing or current_frame is None:
        return jsonify({'status': 'no_analysis'})
    
    # í”„ë ˆì„ ë¶„ì„
    result = analyze_frame(current_frame)
    
    if result and result.get('pose_detected', False):
        # N/A ë“±ê¸‰ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        if result.get('posture_grade') and result.get('posture_grade') != 'N/A':
            try:
                record = RealtimePostureRecord(
                    user_id=current_user.id,
                    detected_side=result.get('detected_side', 'unknown'),
                    ml_confidence=result.get('ml_confidence', 0.0),
                    cva_angle=result.get('cva_angle', 0.0),
                    posture_grade=result.get('posture_grade'),
                    feedback_message=result.get('feedback_message', ''),
                    min_abs_threshold=result.get('min_abs_threshold', 0.0),
                    max_abs_threshold=result.get('max_abs_threshold', 0.0),
                    stage1_threshold=result.get('stage1_threshold', 0.0),
                    frame_count=len(analysis_results) + 1
                )
                
                db.session.add(record)
                db.session.commit()
                
                # ë¶„ì„ ê²°ê³¼ì— ì €ì¥
                analysis_results[record.id] = result
                
            except Exception as e:
                print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì˜¤ë¥˜: {e}")
        else:
            # N/A ë“±ê¸‰ì¸ ê²½ìš° ë¶„ì„ ê²°ê³¼ì—ë§Œ ì €ì¥ (DB ì €ì¥ ì•ˆí•¨)
            analysis_results[f"temp_{len(analysis_results)}"] = result
    
    return jsonify({
        'status': 'success',
        'result': result
    })


@realtime_bp.route('/analysis_history')
@login_required
def analysis_history():
    """ì‹¤ì‹œê°„ ë¶„ì„ íˆìŠ¤í† ë¦¬ í˜ì´ì§€"""
    # ìµœê·¼ 100ê°œì˜ ë¶„ì„ ê¸°ë¡ ì¡°íšŒ
    records = RealtimePostureRecord.query.filter_by(user_id=current_user.id)\
        .order_by(RealtimePostureRecord.timestamp.desc())\
        .limit(100).all()
    
    return render_template('crud/analysis_history.html', records=records)


# ë¶„ì„ê¸° ì´ˆê¸°í™”
initialize_analyzers() 